{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arezoosh/PhD-Course1/blob/master/tweet-preprocessor-portfolio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZtN5QnFtw8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Perform an LDA analysis of the #OKBoomer dataset\n",
        "\n",
        "#Filter the corpus using tweet-preprocessor - try to figure out how to use it using it's documentation Clean up further with SpaCy (keep only ADV, ADJ, NOUN) Use Gensim to build a Dictionary (Filter extremes) and Corpus Use Gensim to run LDA Identify 10 topics Plot topic-counts by day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxOwy6AJuSUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "7e704ac6-5bc3-4771-87a3-58e810aeaeb1"
      },
      "source": [
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/f8/810ec35c31cca89bc4f1a02c14b042b9ec6c19dd21f7ef1876874ef069a6/tweet-preprocessor-0.5.0.tar.gz\n",
            "Building wheels for collected packages: tweet-preprocessor\n",
            "  Building wheel for tweet-preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tweet-preprocessor: filename=tweet_preprocessor-0.5.0-cp36-none-any.whl size=7947 sha256=cc745d278bfa84a3f988aa5886037f0e37b3e620789add34e67bdff25ff26266\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/27/cc/49938e98a2470802ebdefae9d2b3f524768e970c1ebbe2dc4a\n",
            "Successfully built tweet-preprocessor\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUB_-ggLt-mV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import preprocessor as p\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJdOZW0Yt1S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download and open some boomer tweets from trump_tweet_data_archive\n",
        "\n",
        "boomer_tweets_df = pd.read_json('https://github.com/CALDISS-AAU/sdsphd19_coursematerials/raw/master/data/tweets_boomer.zip')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBVpS7gGuqBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boomer_clean = boomer_tweets_df.tweet.map(p.clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obSpYChIvEyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tknzr = TweetTokenizer(strip_handles=True)\n",
        "boomer_tweets_df ['tokenized']= boomer_clean.map(lambda t: tknzr.tokenize(t))\n",
        "boomer_tweets_df ['tokenized']= boomer_tweets_df ['tokenized'].map(lambda t: [token.strip('@') for token in t if token.isalpha()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gUcEZvkyN5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boomer_tweets_df ['tokenized']= boomer_tweets_df ['tokenized'].map(lambda t: ' '.join(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAJRCsItz7NP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upE40M7RyikD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens =[]\n",
        "for tweet in nlp.pipe(boomer_tweets_df ['tokenized']):\n",
        "    proj_tok = [token.lemma_.lower() for token in tweet if token.pos_ in ['NOUN', 'PROPN', 'ADJ', 'ADV'] and not token.is_stop] \n",
        "    tokens.append(proj_tok)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic4xrSEJ0YwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "dc93a93c-152e-4024-b9d9-ad3dd51dca32"
      },
      "source": [
        "boomer_tweets_df ['tokenized_sp']= tokens\n",
        "boomer_tweets_df ['tokenized_sp']\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                 [suddenly]\n",
              "1                                     [role]\n",
              "2                        [allot, old, white]\n",
              "3                    [university, president]\n",
              "4                  [conway, fragile, fossil]\n",
              "                        ...                 \n",
              "10013                                 [lmao]\n",
              "10014                         [good, thread]\n",
              "10015    [boomer, not, new, boss, old, boss]\n",
              "10016                                 [room]\n",
              "10017                                [legit]\n",
              "Name: tokenized_sp, Length: 9722, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVfSxCoW14vB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "297d43d8-47d9-4296-a86e-3ab730944370"
      },
      "source": [
        "!pip install -qq -U gensim"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 24.2MB 99kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVWphXin2D7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4NzWO_32ZXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = Dictionary(boomer_tweets_df['tokenized_sp'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zVN4ULG2-MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filter out low-frequency / high-frequency stuff, also limit the vocabulary to max 1000 words\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.1, keep_n=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2UWdYVH31rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct corpus using this dictionary\n",
        "corpus = [dictionary.doc2bow(doc) for doc in boomer_tweets_df['tokenized_sp']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpRZeWLB4ku5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import LdaMulticore"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMvNCaQw4wrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the model (makes some mess atm due to version clashes)\n",
        "\n",
        "lda_model = LdaMulticore(corpus, id2word=dictionary,  num_topics=10, workers = 4, passes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7vKSjJI5OdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "fdfeaeb3-d084-4cef-86fb-0ef28305f64e"
      },
      "source": [
        "lda_model.print_topics(-1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.019*\"people\" + 0.018*\"boomer\" + 0.011*\"right\" + 0.010*\"generation\" + 0.009*\"moment\" + 0.008*\"perfect\" + 0.008*\"thank\" + 0.007*\"age\" + 0.007*\"point\" + 0.006*\"good\"'),\n",
              " (1,\n",
              "  '0.037*\"way\" + 0.033*\"boomer\" + 0.027*\"meme\" + 0.024*\"people\" + 0.014*\"young\" + 0.013*\"new\" + 0.013*\"old\" + 0.011*\"generation\" + 0.009*\"congratulations\" + 0.009*\"purchase\"'),\n",
              " (2,\n",
              "  '0.032*\"boomer\" + 0.015*\"old\" + 0.009*\"people\" + 0.009*\"time\" + 0.008*\"boomers\" + 0.008*\"generation\" + 0.007*\"millennial\" + 0.007*\"gen\" + 0.006*\"phone\" + 0.006*\"pink\"'),\n",
              " (3,\n",
              "  '0.046*\"t\" + 0.026*\"don\" + 0.016*\"people\" + 0.014*\"cherry\" + 0.011*\"old\" + 0.010*\"boomer\" + 0.009*\"generation\" + 0.009*\"time\" + 0.007*\"young\" + 0.006*\"good\"'),\n",
              " (4,\n",
              "  '0.019*\"people\" + 0.016*\"boomer\" + 0.016*\"time\" + 0.011*\"good\" + 0.011*\"twitter\" + 0.011*\"old\" + 0.011*\"guy\" + 0.010*\"kid\" + 0.010*\"word\" + 0.010*\"thing\"'),\n",
              " (5,\n",
              "  '0.024*\"generation\" + 0.014*\"people\" + 0.010*\"day\" + 0.008*\"right\" + 0.008*\"age\" + 0.008*\"millenial\" + 0.008*\"insult\" + 0.008*\"old\" + 0.007*\"good\" + 0.007*\"new\"'),\n",
              " (6,\n",
              "  '0.022*\"thing\" + 0.018*\"boomer\" + 0.013*\"generation\" + 0.012*\"meme\" + 0.010*\"millennial\" + 0.010*\"time\" + 0.009*\"rich\" + 0.007*\"friend\" + 0.006*\"sure\" + 0.006*\"right\"'),\n",
              " (7,\n",
              "  '0.017*\"old\" + 0.012*\"president\" + 0.010*\"people\" + 0.010*\"boomer\" + 0.009*\"man\" + 0.007*\"disney\" + 0.006*\"day\" + 0.006*\"guy\" + 0.006*\"life\" + 0.006*\"lot\"'),\n",
              " (8,\n",
              "  '0.019*\"boomer\" + 0.010*\"drug\" + 0.010*\"thing\" + 0.009*\"man\" + 0.008*\"biden\" + 0.008*\"candidate\" + 0.008*\"gateway\" + 0.007*\"people\" + 0.007*\"little\" + 0.007*\"generation\"'),\n",
              " (9,\n",
              "  '0.138*\"boomer\" + 0.033*\"ok\" + 0.018*\"millennial\" + 0.015*\"generation\" + 0.014*\"baby\" + 0.011*\"old\" + 0.011*\"thing\" + 0.010*\"boomers\" + 0.009*\"phrase\" + 0.008*\"gen\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ZGq5oD5t0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e35dfeda-7dbd-40e1-bc8a-ef152ed574b2"
      },
      "source": [
        "!pip install -qq pyLDAvis"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.6MB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 42.2MB/s \n",
            "\u001b[?25h  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF_L89So5yPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and import it\n",
        "import pyLDAvis.gensim\n",
        "%matplotlib inline\n",
        "pyLDAvis.enable_notebook()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pivFv8Lq5goD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try to visualize\n",
        "lda_display = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary, sort_topics=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3zMQADQ6AY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyLDAvis.display(lda_display)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHehOcz-6BQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In case you run a website and want to publish it...or embed it in a blogpost...\n",
        "pyLDAvis.save_html(lda_display, 'lda.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UT_Eb866IzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_model[corpus][8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS1Bx4BP6Mas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # that's how you get the topic-number that's ranked highest\n",
        "\n",
        "print(sorted([(2, 0.121567), (9, 0.8610384)], key=lambda x: -x[1]))\n",
        "print(sorted([(2, 0.121567), (9, 0.8610384)], key=lambda x: -x[1])[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}